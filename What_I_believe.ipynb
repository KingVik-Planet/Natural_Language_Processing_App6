{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2ecf4-0886-4dae-867d-2c1a532fb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61767cc9-7de6-443f-a05e-987a92188cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter import files\n",
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b61c09-ed67-433d-a3e2-97c16e129e51",
   "metadata": {},
   "source": [
    "# Load the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ad62a9-0d7b-457f-b421-5c316891a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"What_I_believe.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0404bdc0-c268-4e16-9ebe-9f64807f67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcdfb0-b908-4977-bcdc-f3ab637b1d06",
   "metadata": {},
   "source": [
    "# Accessing or Getting Book Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "571b5b06-c8d7-4be2-a741-06567416a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What I believe\n",
      "Author: Bertrand Russell\n",
      "Release date: June 6, 2024 [eBook #73782]\n",
      "Language: English\n"
     ]
    }
   ],
   "source": [
    "def Book_Info(book, keywords):\n",
    "    lines = book.split('\\n')\n",
    "    for line in lines:\n",
    "        for keyword in keywords:\n",
    "            if  keyword in line:\n",
    "                print(line)\n",
    "keywords = [\"Title\", \"Author\", \"Release date\", \"Language\"]\n",
    "Book_Info(book , keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7fc85-7416-4d08-a3da-89d0468835db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Book_Info(book, Keywords):\n",
    "    lines = book.split('\\n')\n",
    "    while True:\n",
    "        keyword = input(\"Enter a keyword to search or type 'exit' to Stop: \")\n",
    "        if keyword.lower() == 'exit':\n",
    "            break\n",
    "        found = False\n",
    "        for line in lines:\n",
    "            if  keyword in line:\n",
    "                print(line)\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(f\" '{keyword}' does not exit in the '{book}', Please enter another keyword or check properly.\")\n",
    "\n",
    "Book_Info(book, keywords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde00d9-5377-4923-98db-953996a7408b",
   "metadata": {},
   "source": [
    "# Numbers of Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b449646-0663-43c3-aac6-6b6b05c1c191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.count(\"CHAPTER\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2151d8-f4ef-4fe6-a65d-81ad3d3e151a",
   "metadata": {},
   "source": [
    "# With Regular Expression (regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79f38e38-7ba1-4a8a-a404-2a9003002905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67efd381-694a-4a1e-8c15-81992e5086d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'project', 'gutenberg', 'ebook', 'of']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern, book.lower())\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20f05f-f6cc-40e6-a93b-15c91cbba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d  = {}\n",
    "for word in findings:\n",
    "    if word in d.keys():\n",
    "        d[word] = d[word] + 1\n",
    "    else:\n",
    "        d[word] = 1\n",
    "        \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7950356-efd6-464b-831a-fe63e7bb2a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 894), ('project', 88), ('of', 686), ('gutenberg', 97), ('ebook', 13)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list = [(value, key) for (value, key) in d.items()]\n",
    "sorted(d_list[:5], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1fb15-8a9e-4577-a2a5-5c3c60d76e4f",
   "metadata": {},
   "source": [
    "# Checking python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9aa39d0-6e15-43f0-8148-7ae6abbf1f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.1'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02959d4-912c-4fde-9219-631e8e2ddfcd",
   "metadata": {},
   "source": [
    "# Installing nltk libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "561f8298-8cdc-4042-8ded-9b39ca0f65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kingvik planet\\pycharmprojects\\newsapi\\natural_language_processing_app6\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3.11 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31edbcc-d4cc-4512-8e65-57661b4c7dbf",
   "metadata": {},
   "source": [
    "#  Downloading NLTK stopwords corpus to my system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50739f7a-a608-4c56-bc2e-3370907d73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\KingVik\n",
      "[nltk_data]     Planet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74efdf5e-c83e-4527-82fd-9b20683b51ef",
   "metadata": {},
   "source": [
    "# Importing stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0dd4d167-b63d-4e11-9512-3f6514ce1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccfe3f-5d97-402e-a347-b2653f43bdd7",
   "metadata": {},
   "source": [
    "# Listing English Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dc88334-f695-4e99-8cff-c5cadf2a48e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ee00b-f807-4e2a-9c5a-82db18835ad2",
   "metadata": {},
   "source": [
    "# Filtering out the English Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a32ff32-0cd8-4793-bfcb-46faee969423",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_word_list = []\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_word_list.append((count, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "002323e9-2fc5-485c-9590-6a4fd98c337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('youth', 2), ('your', 15), ('young', 6), ('you', 79), ('york', 2)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_word_list = sorted(filtered_word_list, reverse = True)\n",
    "filtered_word_list[:5] # listing First 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fa1ac-eb30-4cbc-a345-cbd5938fa3d4",
   "metadata": {},
   "source": [
    "# Sentimental Analysis: what is the most Positive and Negative Chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "247d9ef0-c101-4eeb-88d7-84064ee2ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\KingVik\n",
      "[nltk_data]     Planet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30002426-71ec-41d0-a9cd-75b5d0c17057",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8822b7a-e8f0-4d1c-bf67-361260e99aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_amplify_ep',\n",
       " '_amplify_qm',\n",
       " '_but_check',\n",
       " '_idioms_check',\n",
       " '_least_check',\n",
       " '_never_check',\n",
       " '_punctuation_emphasis',\n",
       " '_sift_sentiment_scores',\n",
       " 'constants',\n",
       " 'lexicon',\n",
       " 'lexicon_file',\n",
       " 'make_lex_dict',\n",
       " 'polarity_scores',\n",
       " 'score_valence',\n",
       " 'sentiment_valence']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045e258-9ed1-4936-a9be-82cabc089869",
   "metadata": {},
   "source": [
    "# Using Polarity_score find the Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "980a3e07-d9eb-4a16-b236-eac6e39c941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.435, 'pos': 0.565, 'compound': 0.5994}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = analyzer.polarity_scores(\"what a beautiful nosense sunset\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf2cf9-12a3-462a-8044-f29e721df0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scores[\"pos\"] > scores[\"neg\"]:\n",
    "    print(\"Hey, It is a Postive Text\")\n",
    "else:\n",
    "    print(\"Hey, It is a Negative Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01aa110-eb6c-43a6-b700-7663e7c2eba5",
   "metadata": {},
   "source": [
    "# This take an Inputs and Analyse the Inputted words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "111afe66-5201-4250-b01e-c2e22d3e4801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input the word you want to analyze:  How are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Hey, It is a Negative Text\n"
     ]
    }
   ],
   "source": [
    "# Taking user input for the word to analyze\n",
    "word = input(\"Input the word you want to analyze: \")\n",
    "\n",
    "# Analyzing the sentiment of the input word\n",
    "scores = analyzer.polarity_scores(word)\n",
    "print(scores)\n",
    "if scores[\"pos\"] > scores[\"neg\"]:\n",
    "    print(\"Hey, It is a Postive Text\")\n",
    "else:\n",
    "    print(\"Hey, It is a Negative Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe72be44-6052-4ab6-85b4-8181ba8834a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.128, 'neu': 0.714, 'pos': 0.158, 'compound': 1.0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(book)\n",
    "# book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f8818-39aa-45bd-a727-41be7bc171eb",
   "metadata": {},
   "source": [
    "# Find the sentiment analysis of the chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc9edba8-eb38-42fe-a16e-eeeea916706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"CHAPTER [0-9]+\")\n",
    "chapters = re.split(pattern, book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1d53413-bb6e-4dd3-bc85-db8564a57714",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = chapters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d0dbd10-e43f-4fa8-ad21-b4e1af72ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'neg': 0.128, 'neu': 0.714, 'pos': 0.158, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for nr, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(nr + 1, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3d12ab3b-107b-405f-b307-454d8ff14684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 : {'neg': 0.017, 'neu': 0.921, 'pos': 0.062, 'compound': 0.9731}\n",
      "Chapter 2 : {'neg': 0.108, 'neu': 0.757, 'pos': 0.135, 'compound': 0.9963}\n",
      "Chapter 3 : {'neg': 0.14, 'neu': 0.654, 'pos': 0.206, 'compound': 0.9999}\n",
      "Chapter 4 : {'neg': 0.116, 'neu': 0.703, 'pos': 0.181, 'compound': 0.9988}\n",
      "Chapter 5 : {'neg': 0.116, 'neu': 0.734, 'pos': 0.15, 'compound': 0.9998}\n"
     ]
    }
   ],
   "source": [
    "# Listing the Chapters\n",
    "for nr, chapter in enumerate(chapters, start=1):  # Start counting from 1\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(\"Chapter\", nr, \":\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a25b5c5c-785f-4921-99ad-f3ac20d1c65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 : {'neg': 0.017, 'neu': 0.921, 'pos': 0.062, 'compound': 0.9731}\n",
      "Chapter 2 : {'neg': 0.108, 'neu': 0.757, 'pos': 0.135, 'compound': 0.9963}\n",
      "Chapter 3 : {'neg': 0.14, 'neu': 0.654, 'pos': 0.206, 'compound': 0.9999}\n",
      "Chapter 4 : {'neg': 0.116, 'neu': 0.703, 'pos': 0.181, 'compound': 0.9988}\n",
      "Chapter 5 : {'neg': 0.116, 'neu': 0.734, 'pos': 0.15, 'compound': 0.9998}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Listing the Chapters\n",
    "    for nr, chapter in enumerate(chapters, start=1):  # Start counting from 1\n",
    "        scores = analyzer.polarity_scores(chapter)\n",
    "        print(\"Chapter\", nr, \":\", scores)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4932dc-8565-4bb5-b061-cdb9541321df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
